{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd70c903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Vosk model...\n",
      " Listening... (Ctrl+C to stop)\n",
      "Partial: for example\n",
      "Partial: for example\n",
      "Partial: for example\n",
      "Partial: for example\n",
      "Partial: for example\n",
      "Partial: for example\n",
      "Partial: for example\n",
      "Partial: for example\n",
      "Partial: for example\n",
      "Partial: for example\n",
      " Final: for example\n",
      "Partial: i\n",
      "Partial: i\n",
      "Partial: i am\n",
      "Partial: i am\n",
      "Partial: i am a\n",
      "Partial: i am a\n",
      "Partial: i am a\n",
      "Partial: i am a\n",
      "Partial: i am a program\n",
      "Partial: i am a program\n",
      "Partial: i am a program\n",
      "Partial: i am a program\n",
      " Final: i am a program\n",
      "Partial: machete\n",
      "Partial: machete\n",
      "Partial: the church in the\n",
      "Partial: the church in the\n",
      "Partial: the church in the\n",
      "Partial: the church in the\n",
      "Partial: the church in there is a\n",
      "Partial: the church in there is a\n",
      "Partial: the church in there is a\n",
      "Partial: the church in there is a\n",
      "Partial: the church in the desert a\n",
      "Partial: the church in the desert a\n",
      "Partial: the church in the desert a\n",
      "Partial: the church in the desert a\n",
      "Partial: the church in the desert a\n",
      " Final: the church in the desert\n",
      "Partial: swish it\n",
      "Partial: swish it\n",
      "Partial: swish it is\n",
      "Partial: swish it is\n",
      "\n",
      "--- Latency Report ---\n",
      "Partial: {'count': 41, 'avg_latency': 62.3, 'median latency': 28.8, '90th percentile latency': np.float64(166.8)}\n",
      "Final  : {'count': 3, 'avg_latency': 24.0, 'median latency': 25.4, '90th percentile latency': np.float64(25.9)}\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import queue, json, time, statistics\n",
    "import numpy as np\n",
    "import noisereduce as nr\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "# ===== Params =====\n",
    "SAMPLE_RATE = 16000\n",
    "CHUNK_SIZE  = 2000      # 2000–4000; 2000 ≈ 125 ms blok\n",
    "MODEL_PATH  = r\"C:\\Users\\Admin\\Desktop\\vosk-model-small-en-us-0.15\"\n",
    "\n",
    "print(\"Loading Vosk model...\")\n",
    "model = Model(MODEL_PATH)\n",
    "recognizer = KaldiRecognizer(model, SAMPLE_RATE)\n",
    "\n",
    "q = queue.Queue()\n",
    "latencies_partial = []\n",
    "latencies_final   = []\n",
    "\n",
    "def callback(indata, frames, time_info, status):\n",
    "    if status:\n",
    "        print(status, flush=True)\n",
    "    # Blokun capture vaxtını daxil edirik\n",
    "    q.put((bytes(indata), time.time()))\n",
    "\n",
    "def main():\n",
    "    print(\" Listening... (Ctrl+C to stop)\")\n",
    "    with sd.RawInputStream(samplerate=SAMPLE_RATE, blocksize=CHUNK_SIZE,\n",
    "                           dtype='int16', channels=1, callback=callback):\n",
    "        while True:\n",
    "            data, t_captured = q.get()\n",
    "\n",
    "            # numpy\n",
    "            audio = np.frombuffer(data, dtype=np.int16)\n",
    "\n",
    "            # noise reduce (light)\n",
    "            reduced = nr.reduce_noise(y=audio, sr=SAMPLE_RATE, prop_decrease=0.9, stationary=False, n_std_thresh_stationary=1.5)\n",
    "            processed = reduced.astype(np.int16).tobytes()\n",
    "\n",
    "            t_start = time.time()\n",
    "            accepted = recognizer.AcceptWaveform(processed)\n",
    "            t_decoded = time.time()\n",
    "\n",
    "            if accepted:\n",
    "                result = json.loads(recognizer.Result())\n",
    "                text = result.get(\"text\", \"\").strip()\n",
    "                if text:\n",
    "                    # Latency ölç: blok capture → final hazır\n",
    "                    latencies_final.append(t_decoded - t_captured)\n",
    "                    print(f\" Final: {text}\")\n",
    "            else:\n",
    "                partial = json.loads(recognizer.PartialResult())\n",
    "                p = partial.get(\"partial\", \"\").strip()\n",
    "                if p:\n",
    "                    # Partial latency: blok capture → partial hazır\n",
    "                    latencies_partial.append(t_decoded - t_captured)\n",
    "                    print(f\"Partial: {p}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        # Session bitəndə latency statistikası\n",
    "        def stat(arr):\n",
    "            return {\n",
    "                \"count\": len(arr),\n",
    "                \"avg_latency\": round(1000 * (sum(arr)/len(arr)), 1) if arr else None,\n",
    "                \"median latency\": round(1000 * statistics.median(arr), 1) if arr else None,\n",
    "                \"90th percentile latency\": round(1000 * np.percentile(arr, 90), 1) if arr else None\n",
    "            }\n",
    "        print(\"\\n--- Latency Report ---\")\n",
    "        print(\"Partial:\", stat(latencies_partial))\n",
    "        print(\"Final  :\", stat(latencies_final))\n",
    "        print(\"Finished!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
